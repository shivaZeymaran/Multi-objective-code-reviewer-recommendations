{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyProject.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8J1aB34OT2vv",
        "bgCIXkyJXg43",
        "iJv6aqisdePZ",
        "VnDL2S8t4q2V",
        "Slk7yWpWfrdw",
        "scd43oQFNoYC",
        "8FcG8-Ql0R2w",
        "DiQ3eg8h3Z7c",
        "EyhwlHRy6X7p",
        "F8WFK4WOB32c",
        "UaZ0rQH7rXw4",
        "ER-OFM84BxeM",
        "Q2Nlv7-tC6QO",
        "_gYyVF1sDCMl",
        "yEpoQld9DL2-",
        "dmtDa9wLDRd2",
        "pQ0OzQGlNNkI",
        "HTzNT27Dwsgt",
        "WSVDjK4ow2Gk",
        "vi_k1x69BZH3",
        "NO6ZgCoBIX70"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DMH1PQiSrhi"
      },
      "source": [
        "import os\n",
        "from numpy import *\n",
        "import json\n",
        "import pandas as pd\n",
        "from random import *\n",
        "import math\n",
        "from datetime import *\n",
        "from dateutil import parser\n",
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0sbZPFbSs_6",
        "outputId": "4e57f844-7f02-4d2e-ada6-3a2052d0f358"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J1aB34OT2vv"
      },
      "source": [
        "# Get required data\n",
        "From the github repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YncyX3P4Suzu",
        "outputId": "069bd7d6-b3bb-4034-d563-00f0520087d1"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/XLipcak/rev-rec.git cloned-repo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'cloned-repo'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 1170, done.\u001b[K\n",
            "remote: Total 1170 (delta 0), reused 0 (delta 0), pack-reused 1170\u001b[K\n",
            "Receiving objects: 100% (1170/1170), 45.11 MiB | 14.96 MiB/s, done.\n",
            "Resolving deltas: 100% (503/503), done.\n",
            "Checking out files: 100% (88/88), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUO0DfuaS8_2",
        "outputId": "4ea632d0-b18d-4b7a-8d2e-7a0ef2527889"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mcloned-repo\u001b[0m/  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovkSscBBS75P",
        "outputId": "96896c2f-6bd4-48e7-b491-6afbdb18df23"
      },
      "source": [
        "# Save OpenStack dataset\n",
        "import shutil\n",
        "src = \"/content/cloned-repo/rev-rec-data/openstack.json\"\n",
        "dst = \"/content/drive/MyDrive/Colab Notebooks/My Project/openstack.json\"\n",
        "shutil.move(src, dst)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/My Project/openstack.json'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgCIXkyJXg43"
      },
      "source": [
        "# Process raw data \n",
        "a JSON file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYaj-H2BTHN2",
        "outputId": "dd9b664e-04a8-4420-aae2-1d1d51f11f57"
      },
      "source": [
        "f = open('/content/drive/MyDrive/Colab Notebooks/My Project/openstack.json',)\n",
        "data = json.load(f)  # returns json object as a dictionary\n",
        "for i in range(5):   # 5 first elements of the json list\n",
        "    print(data[i])\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'subProject': 'openstack/tempest', 'changeId': 'I9e7b9a2491d6a3f01d71551e4cadcccf154d992d', 'changeNumber': 6139, 'timestamp': 1333428006000, 'reviewers': [{'accountId': '97', 'email': 'daryl.walleck@rackspace.com', 'name': 'Daryl Walleck', 'avatar': None}, {'accountId': '7', 'email': 'jaypipes@gmail.com', 'name': 'Jay Pipes', 'avatar': None}], 'owner': {'accountId': '2238', 'email': 'rajalakshmi.girish@hpe.com', 'name': 'rajalakshmi-ganesan', 'avatar': None}, 'filePaths': [{'location': 'tempest/tests/test_volumes_get.py'}]}\n",
            "{'subProject': 'openstack/tempest', 'changeId': 'I10e7116570f922ec87e23b1f880cd4b1c08c3088', 'changeNumber': 7438, 'timestamp': 1337072165000, 'reviewers': [{'accountId': '97', 'email': 'daryl.walleck@rackspace.com', 'name': 'Daryl Walleck', 'avatar': None}, {'accountId': '7', 'email': 'jaypipes@gmail.com', 'name': 'Jay Pipes', 'avatar': None}], 'owner': {'accountId': '4120', 'email': 'rohit.karajgi@ril.com', 'name': 'Rohit Karajgi', 'avatar': None}, 'filePaths': [{'location': 'tempest/tests/identity/test_roles.py'}, {'location': 'tempest/services/identity/json/admin_client.py'}, {'location': 'tempest/tests/identity/base_admin_test.py'}]}\n",
            "{'subProject': 'openstack/nova', 'changeId': 'I1d0c395cf679e07e304dd878d97734307b685f4c', 'changeNumber': 7951, 'timestamp': 1338410316000, 'reviewers': [{'accountId': '679', 'email': 'klmitch@mit.edu', 'name': 'Kevin L. Mitchell', 'avatar': None}, {'accountId': '1561', 'email': 'rbryant@redhat.com', 'name': 'Russell Bryant', 'avatar': None}], 'owner': {'accountId': '1849', 'email': 'joe.gordon0@gmail.com', 'name': 'Joe Gordon', 'avatar': None}, 'filePaths': [{'location': '.gitignore'}]}\n",
            "{'subProject': 'openstack/nova', 'changeId': 'Ia151f265bf62e6704de6cc2f2c01963be9e2dd69', 'changeNumber': 7765, 'timestamp': 1337879042000, 'reviewers': [{'accountId': '1561', 'email': 'rbryant@redhat.com', 'name': 'Russell Bryant', 'avatar': None}, {'accountId': '357', 'email': 'devin@openstack.org', 'name': 'Devin Carlen', 'avatar': None}], 'owner': {'accountId': '1849', 'email': 'joe.gordon0@gmail.com', 'name': 'Joe Gordon', 'avatar': None}, 'filePaths': [{'location': 'tools/hacking.py'}]}\n",
            "{'subProject': 'openstack/nova', 'changeId': 'Ie4cfec6f89d6b37554b5345cde92f982397915e2', 'changeNumber': 7807, 'timestamp': 1337967413000, 'reviewers': [{'accountId': '1561', 'email': 'rbryant@redhat.com', 'name': 'Russell Bryant', 'avatar': None}, {'accountId': '357', 'email': 'devin@openstack.org', 'name': 'Devin Carlen', 'avatar': None}], 'owner': {'accountId': '2', 'email': 'mordred@inaugust.com', 'name': 'Monty Taylor', 'avatar': None}, 'filePaths': [{'location': 'tox.ini'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJv6aqisdePZ"
      },
      "source": [
        "## Hands on with given data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7AGHyP4ZAZH",
        "outputId": "4c34b2e2-32b8-400d-a6bb-e8cbb57cf12f"
      },
      "source": [
        "type(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT6NArSMZ2hB",
        "outputId": "f594842b-5b23-4f37-f516-5807aa31d7be"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6545"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zyDNbX2Z9k_",
        "outputId": "3152932e-4139-4ced-f10c-8391b17679e1"
      },
      "source": [
        "# get an element of the list of data\n",
        "data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'changeId': 'I9e7b9a2491d6a3f01d71551e4cadcccf154d992d',\n",
              " 'changeNumber': 6139,\n",
              " 'filePaths': [{'location': 'tempest/tests/test_volumes_get.py'}],\n",
              " 'owner': {'accountId': '2238',\n",
              "  'avatar': None,\n",
              "  'email': 'rajalakshmi.girish@hpe.com',\n",
              "  'name': 'rajalakshmi-ganesan'},\n",
              " 'reviewers': [{'accountId': '97',\n",
              "   'avatar': None,\n",
              "   'email': 'daryl.walleck@rackspace.com',\n",
              "   'name': 'Daryl Walleck'},\n",
              "  {'accountId': '7',\n",
              "   'avatar': None,\n",
              "   'email': 'jaypipes@gmail.com',\n",
              "   'name': 'Jay Pipes'}],\n",
              " 'subProject': 'openstack/tempest',\n",
              " 'timestamp': 1333428006000}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwVmnNz6aQQY",
        "outputId": "c88e3b76-9e76-481b-cef5-daa1d389bf52"
      },
      "source": [
        "# read a single feature of an element\n",
        "data[0]['reviewers']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'accountId': '97',\n",
              "  'avatar': None,\n",
              "  'email': 'daryl.walleck@rackspace.com',\n",
              "  'name': 'Daryl Walleck'},\n",
              " {'accountId': '7',\n",
              "  'avatar': None,\n",
              "  'email': 'jaypipes@gmail.com',\n",
              "  'name': 'Jay Pipes'}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnDL2S8t4q2V"
      },
      "source": [
        "## Cleaning data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcqqHao6eqFR",
        "outputId": "c58b872c-2a49-49ad-cff6-fe5f160650d8"
      },
      "source": [
        "# Extract and save desired features from each pull request. The new desired data is new_data\n",
        "new_data = []\n",
        "\n",
        "for i in range(0, len(data)):\n",
        "  elem_dict = {\"changeId\":data[i]['changeId'], \"reviewers\":data[i]['reviewers'], \"owner\":data[i]['owner'], \"filePaths\":data[i]['filePaths'], \"time\":data[i]['timestamp']}\n",
        "  new_data.append(elem_dict)\n",
        "  # print(new_data[i])\n",
        "\n",
        "print(len(new_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVBJ2Q1n62P2",
        "outputId": "b3a6377d-2ecd-41d1-e498-9f7fbb59972f"
      },
      "source": [
        "new_data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'changeId': 'I9e7b9a2491d6a3f01d71551e4cadcccf154d992d',\n",
              " 'filePaths': [{'location': 'tempest/tests/test_volumes_get.py'}],\n",
              " 'owner': {'accountId': '2238',\n",
              "  'avatar': None,\n",
              "  'email': 'rajalakshmi.girish@hpe.com',\n",
              "  'name': 'rajalakshmi-ganesan'},\n",
              " 'reviewers': [{'accountId': '97',\n",
              "   'avatar': None,\n",
              "   'email': 'daryl.walleck@rackspace.com',\n",
              "   'name': 'Daryl Walleck'},\n",
              "  {'accountId': '7',\n",
              "   'avatar': None,\n",
              "   'email': 'jaypipes@gmail.com',\n",
              "   'name': 'Jay Pipes'}],\n",
              " 'time': 1333428006000}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1jslJtq759N",
        "outputId": "f2a986fe-a28a-4961-9a16-31d1a4190bba"
      },
      "source": [
        "# Remove remaining undesired features. The final desired information is saved in final_data\n",
        "final_data = []\n",
        "\n",
        "for i in range(0, len(new_data)):\n",
        "  elem_dict = {\"time\":new_data[i]['time'], \"changeId\":new_data[i]['changeId'], \"ownerId\": new_data[i]['owner']['accountId'], \"reviewersId\":[], \"filePaths\":[]}\n",
        "\n",
        "  for j in range(0, len(new_data[i]['reviewers'])):\n",
        "    elem_dict[\"reviewersId\"].append(new_data[i]['reviewers'][j]['accountId'])\n",
        "\n",
        "  for j in range(0, len(new_data[i]['filePaths'])):\n",
        "    elem_dict[\"filePaths\"].append(new_data[i]['filePaths'][j]['location'])\n",
        "  \n",
        "  final_data.append(elem_dict)\n",
        "  # print(final_data[i])\n",
        "\n",
        "print(len(final_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVK0wQRC_mMI",
        "outputId": "054beb21-8354-42e2-a5bf-89646c8d25f4"
      },
      "source": [
        "final_data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'changeId': 'I9e7b9a2491d6a3f01d71551e4cadcccf154d992d',\n",
              " 'filePaths': ['tempest/tests/test_volumes_get.py'],\n",
              " 'ownerId': '2238',\n",
              " 'reviewersId': ['97', '7'],\n",
              " 'time': 1333428006000}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebjq1N8RJ_YR"
      },
      "source": [
        "# change timestamp value from int to date format\n",
        "for pr in final_data:\n",
        "  timestamp = int(pr['time']/1000)  # removing the 3 last zero digits \n",
        "  dt_obj = datetime.fromtimestamp(timestamp) \n",
        "  pr['time'] = dt_obj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofFuDQxFK6sy",
        "outputId": "a3eb1eb8-0e96-4806-ce40-32844f0704c1"
      },
      "source": [
        "final_data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'changeId': 'I9e7b9a2491d6a3f01d71551e4cadcccf154d992d',\n",
              " 'filePaths': ['tempest/tests/test_volumes_get.py'],\n",
              " 'ownerId': '2238',\n",
              " 'reviewersId': ['97', '7'],\n",
              " 'time': datetime.datetime(2012, 4, 3, 4, 40, 6)}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enh50GDlvdg4",
        "outputId": "7dd4a38b-89b9-4c54-da1a-115e07ad756f"
      },
      "source": [
        "# sort data by time\n",
        "sorted_data = sorted(final_data, key=lambda d: d['time'])\n",
        "\n",
        "# Get the Time of available data from selected project\n",
        "print(\"Start date:\", sorted_data[0]['time'])\n",
        "print(\"End date:\", sorted_data[-1]['time'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start date: 2011-07-18 15:43:34\n",
            "End date: 2012-05-30 21:39:57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BqZjVtrwpj9"
      },
      "source": [
        "The openstack data that we use in here, containes about 10 months information of openstack project (2011-2012)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFmjc100GumD",
        "outputId": "94c96853-9b52-4b14-9582-6bac1f8878eb"
      },
      "source": [
        "type(sorted_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNTdHBiGI3EP"
      },
      "source": [
        "# Convert list to json\n",
        "# It should be a string before write it to file\n",
        "# \"default\" is added to dumps to make anything not serializable for JSON to string format (like datatime) \n",
        "json_string = json.dumps(sorted_data, default=str) \n",
        "\n",
        "# Save OpenStack new dataset\n",
        "file = open('openstack_final.json', 'w')\n",
        "file.write(json_string)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGjuswdSJKrP",
        "outputId": "93de5d4b-2d72-4de2-a1c1-c0b729c607ca"
      },
      "source": [
        "# Move OpenStack dataset to proper location\n",
        "import shutil\n",
        "\n",
        "src = \"./openstack_final.json\"\n",
        "dst = \"/content/drive/MyDrive/Colab Notebooks/My Project/openstack_final.json\"\n",
        "shutil.move(src, dst)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/My Project/openstack_final.json'"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrepSN13fjWp"
      },
      "source": [
        "# Approach\n",
        "\n",
        "Should run the code each time from this part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Slk7yWpWfrdw"
      },
      "source": [
        "## Main components of the approach\n",
        "Extract 3 interaction metrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scd43oQFNoYC"
      },
      "source": [
        "### Reviewer's **expertise** model\n",
        "FR matrix\n",
        "as 'cal_expertise' function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0EO-lXkfrPB"
      },
      "source": [
        "# Function to extract 'Expertise' metrix\n",
        "# Returns P*M matrix named FR\n",
        "def cal_expertise(files, all_reviewers, train):\n",
        "  FR = array([[0]*len(all_reviewers)] * len(files))\n",
        "\n",
        "  # fill the cells of the dataframe by checking PRs one by one\n",
        "  for f in files:\n",
        "    for pr in train:\n",
        "      if f in pr['filePaths']:\n",
        "        for r in pr['reviewersId']:\n",
        "          FR[files.index(f)][all_reviewers.index(r)] += 1\n",
        "\n",
        "  return FR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FcG8-Ql0R2w"
      },
      "source": [
        "### Reviewerâ€‘developer **collaboration** model\n",
        "DR matrix\n",
        "as 'cal_collaboration' function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfRPBPF-OXSc"
      },
      "source": [
        "# Function to extract 'Collaboration' metrix\n",
        "# Returns N*M matrix named DR\n",
        "def cal_collaboration(all_devs, all_reviewers, train):\n",
        "  DR = array([[0]*len(all_reviewers)] * len(all_devs))\n",
        "\n",
        "  # fill the values of dataframe by checking PRs one by one\n",
        "  for pr in train:\n",
        "    for r in pr['reviewersId']:\n",
        "      DR[all_devs.index(pr['ownerId'])][all_reviewers.index(r)] += len(pr['filePaths'])\n",
        "\n",
        "  return DR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiQ3eg8h3Z7c"
      },
      "source": [
        "### **Availability** model\n",
        "as 'cal_availability' function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmTt3eRoE6z6"
      },
      "source": [
        "# Function to extract 'Availability' vector\n",
        "# Returns 1*M matrix named A \n",
        "def cal_availability(all_reviewers, train, cur_time):\n",
        "\n",
        "  # seven day before the time of our test PR\n",
        "  week_ago = cur_time - timedelta(days=7)\n",
        "  \n",
        "  # Extract a list of PRs that are between time of seven days ago up to the time of test PR\n",
        "  week_pr = [pr for pr in train if (week_ago < pr['time'] < cur_time)]\n",
        "  # print(\"Num of PRs in last 7 days:\", len(week_pr))\n",
        "\n",
        "  # Extract the availability matrix named 'A' that is 1*M\n",
        "  A = array([0]*len(all_reviewers))\n",
        "  for r in all_reviewers:\n",
        "    for pr in week_pr:\n",
        "      if r in pr['reviewersId']:\n",
        "        A[all_reviewers.index(r)] += len(pr['filePaths'])\n",
        "  \n",
        "  return A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyhwlHRy6X7p"
      },
      "source": [
        "### **File-Developer** matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmqibzIQ62UI"
      },
      "source": [
        "# Function to extract File-Developer matrix\n",
        "# Returns N*P matrix named FD \n",
        "def cal_fileDev(all_devs, files, train):\n",
        "  FD = array([[0]*len(files)] * len(all_devs))\n",
        "\n",
        "  # Fill the dataframe with number of times each developer worked on each file\n",
        "  for pr in train:\n",
        "    for f in pr['filePaths']:\n",
        "      if f in files:\n",
        "        FD[all_devs.index(pr['ownerId'])][files.index(f)] += 1\n",
        "\n",
        "  return FD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8WFK4WOB32c"
      },
      "source": [
        "## Fitness functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy5dCh16bc1s"
      },
      "source": [
        "def fit_avail(A, S):\n",
        "  avail = sum(dot(A, S.T))\n",
        "  return divide(1, avail, where=(avail!=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoT2PmB5x5lR"
      },
      "source": [
        "def fit_expert(FR, S):\n",
        "  return sum(divide(FR, S, out=zeros_like(FR, dtype=float), where=(S!=0)))\n",
        "\n",
        "################### Alternative #######################\n",
        "# PR matrix that is file priority will set to all zeros (because there is no priority tag)\n",
        "  # PR = len(files)*[0]\n",
        "  # Expertise = 0\n",
        "  # for k in range(0, len(files)):\n",
        "  #   for i in range(0, len(all_reviewers)):\n",
        "  #     if S[k][i] > 0:\n",
        "  #       Expertise += ((FR[k][i] + PR[k]) / S[k][i])\n",
        "  # return Expertise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGmWk514NWam"
      },
      "source": [
        "def fit_collab(P, M, N, DR, FD, S):\n",
        "  return sum([DR[k][i]*FD[k][j] for k in range(N) for j in range(P) for i in range(M) if S[j][i]>0])\n",
        "\n",
        "################### Alternative #######################\n",
        "# Collaboration = 0\n",
        "# for k in range(0, N):\n",
        "#   for j in range(0, P):\n",
        "#     for i in range(0, M):\n",
        "#       if S[j][i]>0:\n",
        "#         Collaboration += (DR[k][i]*FD[k][j])\n",
        "# return Collaboration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaZ0rQH7rXw4"
      },
      "source": [
        "## Genetic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER-OFM84BxeM"
      },
      "source": [
        "### Chromosome defenition\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRIO1je4qFWp"
      },
      "source": [
        "# Chromosome creation\n",
        "# Reviewer-File matrix named S with shape of P*M \n",
        "\n",
        "def init_gene(P, M):\n",
        "  S = array([[0]*M] * P)\n",
        "\n",
        "  # assign random number to each cell of the dataframe\n",
        "  # each \"row\" must have all the integer numbers from 0 to M (distinct numbers)\n",
        "  for row in range(0, P):\n",
        "    num_of_zeros = randint(0, M-1)   # we should choose atleast one reviewer (no row with all zeros)\n",
        "    # print(\"number of zero ranks in row\", row, \"is:\", num_of_zeros)\n",
        "    rand_ranks = num_of_zeros * [0]\n",
        "    rand_ranks.extend(sample(range(1, M-num_of_zeros+1), M-num_of_zeros))  # sampling without replacement\n",
        "    # print(\"number of non-zero ranks in row\", row, \"is:\", max(rand_ranks))\n",
        "    shuffle(rand_ranks)   # Shuffle zeros with non-zero ranks\n",
        "    S[row] = rand_ranks\n",
        "  \n",
        "  return S"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2Nlv7-tC6QO"
      },
      "source": [
        "### Offspring creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVyHiRhmrpln"
      },
      "source": [
        "# Swap mutation function\n",
        "def mutation(gene, mute_prob, modif_prob, P):\n",
        "  r = random()\n",
        "  if r < mute_prob:\n",
        "    # mutation can accure at each row with some probability\n",
        "    dict_rows = {}  # dictionary of selected rows for mutation and their probability\n",
        "    for i in range(0, P): \n",
        "      rand = random()\n",
        "      if rand < modif_prob:\n",
        "        dict_rows[i] = rand   # this row added to selected rows for mutation process\n",
        "    # print(\"rows number for swapping\", dict_rows)\n",
        "\n",
        "    if len(dict_rows) > 1:  # if two or more rows selected\n",
        "      # find two rows with maximum probabilities (sort dictionary by values in descending order)\n",
        "      sort_dict = sorted(dict_rows.items(), key=lambda x: x[1], reverse=True)\n",
        "      r1, r2 = sort_dict[0][0], sort_dict[1][0]\n",
        "      # print(\"selected rows for swapping:\", r1, r2)\n",
        "      # swapping these two rows\n",
        "      gene[[r1, r2]] = gene[[r2, r1]]\n",
        "    \n",
        "  return gene"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrVVdOzVb0v9"
      },
      "source": [
        "# Function to repaire genes with infeasible ranks\n",
        "# This function not change the gene if it is a feasible solution\n",
        "# the repair mechanism just apply on the mixed row of the child\n",
        "def repair_gene(gene):\n",
        "  non_zero_vals = gene[(gene!=0)]   # non zero elements of gene matrix\n",
        "  non_zero_vals.sort()\n",
        "  new_vals = [i for i in range(1, len(non_zero_vals)+1)]   # new elements for repaired gene\n",
        "\n",
        "  dic = dict(zip(new_vals, non_zero_vals))  # create a dictionary of new values to previous one\n",
        "  key_list, val_list = list(dic.keys()), list(dic.values())\n",
        "\n",
        "  # replace gene elements with repaired ones according to dictionary\n",
        "  for i in range(0, len(gene)):\n",
        "    if gene[i] != 0:\n",
        "      position = val_list.index(gene[i])\n",
        "      val_list.remove(gene[i])\n",
        "      gene[i] = key_list[position]\n",
        "      key_list.remove(key_list[position])\n",
        "\n",
        "  # return repaired gene\n",
        "  return gene"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a0DpZmyb5Be"
      },
      "source": [
        "# Single point crossover function\n",
        "def crossover(gene1, gene2, cross_prob, mute_prob, modif_prob, P, M):\n",
        "  childs = []\n",
        "  r = random()  # random number between 0 and 1\n",
        "  if r < cross_prob:\n",
        "    # crossover point\n",
        "    row, col = randint(0, P-1), randint(0, M-1)   \n",
        "    # print(\"crossover point\", row, col)\n",
        "\n",
        "    # first child : (0, 0) to (row, col) from first parent and the rest from second parent\n",
        "    child1 = gene1[0:row, :]\n",
        "    child1 = append(append(append(child1, gene1[row, 0:col]), gene2[row, col:]), gene2[row+1:, :]).reshape((P, M))\n",
        "    # second child : first part from parent2 and second part from parent1\n",
        "    child2 = gene2[0:row, :]\n",
        "    child2 = append(append(append(child2, gene2[row, 0:col]), gene1[row, col:]), gene1[row+1:, :]).reshape((P, M))\n",
        "    # print(\"child1 before repair\", child1)\n",
        "    # print(\"child2 before repair\", child2)\n",
        "\n",
        "    # repair mechanism on mixed row of each child\n",
        "    child1[row] = repair_gene(child1[row])\n",
        "    child2[row] = repair_gene(child2[row])\n",
        "    # print(\"child1 after repair\", child1)\n",
        "    # print(\"child2 after repair\", child2)\n",
        "\n",
        "    # mutation\n",
        "    child1 = mutation(child1, mute_prob, modif_prob, P)\n",
        "    # print(\"child1 after mutation\", child1)\n",
        "    child2 = mutation(child2, mute_prob, modif_prob, P)\n",
        "    # print(\"child2 after mutation\", child2)\n",
        "\n",
        "    childs.append(child1)\n",
        "    childs.append(child2)\n",
        "\n",
        "  return childs     # it returns empty list when no crossover happend"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_r7iXdVb-Rd"
      },
      "source": [
        "def create_new_pop(P0, pop_size, cross_prob, mute_prob, modif_prob, P, M):\n",
        "  childs = []\n",
        "  while len(childs) < pop_size:\n",
        "    gene1 = P0[randint(0, pop_size-1)]\n",
        "    # print(\"first parent\", gene1)\n",
        "    gene2 = P0[randint(0, pop_size-1)]\n",
        "    # print(\"second parent\", gene2)\n",
        "    child1_2 = crossover(gene1, gene2, cross_prob, mute_prob, modif_prob, P, M)\n",
        "    if len(child1_2)!=0:\n",
        "      childs.append(child1_2[0])\n",
        "      childs.append(child1_2[1])\n",
        "    # print(\"childs up to now\", childs)\n",
        "    # print(\"-----------------next loop-------------------\")\n",
        "  return childs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gYyVF1sDCMl"
      },
      "source": [
        "### Non-domination Rank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyuoUlPEcCCV"
      },
      "source": [
        "def dominate(a, b, avail_values, expert_values, collab_values):\n",
        "  if ((avail_values[a] > avail_values[b] and expert_values[a] > expert_values[b] and collab_values[a] < collab_values[b])\n",
        "      or (avail_values[a] >= avail_values[b] and expert_values[a] >  expert_values[b] and collab_values[a] <  collab_values[b]) \n",
        "      or (avail_values[a] >  avail_values[b] and expert_values[a] >= expert_values[b] and collab_values[a] <  collab_values[b])\n",
        "      or (avail_values[a] >  avail_values[b] and expert_values[a] >  expert_values[b] and collab_values[a] <= collab_values[b])\n",
        "      or (avail_values[a] >= avail_values[b] and expert_values[a] >= expert_values[b] and collab_values[a] <  collab_values[b])\n",
        "      or (avail_values[a] >= avail_values[b] and expert_values[a] >  expert_values[b] and collab_values[a] <= collab_values[b])\n",
        "      or (avail_values[a] >  avail_values[b] and expert_values[a] >= expert_values[b] and collab_values[a] <= collab_values[b])):\n",
        "    return True   # a dominates b\n",
        "  else:\n",
        "    return False "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgKUDUBmcFxU"
      },
      "source": [
        "def fast_non_dominated_sort(avail_values, expert_values, collab_values):\n",
        "  pop = len(avail_values)   # population\n",
        "  S = [[] for i in range(0, pop)]  # means who are you dominating\n",
        "  n = [0 for i in range(0, pop)]   # means how many people dominate you\n",
        "  fronts = [[]]  # Pareto-fornts\n",
        "\n",
        "  # fill S and n lists for each gene\n",
        "  for p in range(0, pop):\n",
        "    for q in range(p+1, pop):\n",
        "      if dominate(p, q, avail_values, expert_values, collab_values):   # p dominates q\n",
        "        if q not in S[p]:\n",
        "          S[p].append(q)\n",
        "        n[q] += 1\n",
        "      elif dominate(q, p, avail_values, expert_values, collab_values): # q dominates p\n",
        "        n[p] += 1\n",
        "        if p not in S[q]:\n",
        "          S[q].append(p)\n",
        "\n",
        "    if n[p] == 0:\n",
        "      if p not in fronts[0]:\n",
        "        fronts[0].append(p)\n",
        "    # print(\"chromosome number\", p, \"S is:\", S[p], \"n is:\", n[p])\n",
        "\n",
        "  # calculate other front levels of the remaining population\n",
        "  i = 0\n",
        "  while(fronts[i] != []):\n",
        "    Q = []\n",
        "    for p in fronts[i]:\n",
        "      for q in S[p]:\n",
        "        n[q] -= 1\n",
        "        if n[q] == 0:\n",
        "          if q not in Q:\n",
        "            Q.append(q)\n",
        "    i = i+1\n",
        "    fronts.append(Q)\n",
        "\n",
        "  del fronts[len(fronts)-1]  # delete one last empty level added to front levels\n",
        "  return fronts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEpoQld9DL2-"
      },
      "source": [
        "### Crowding Distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B77yDH-dcL6W"
      },
      "source": [
        "def crowding_distance(avail_values, expert_values, collab_values, front):\n",
        "  distances = [0.0] * len(avail_values)\n",
        "\n",
        "  # crowd: [([obj_1, obj_2, ...], i_0), ([obj_1, obj_2, ...], i_1), ...]\n",
        "  crowd = [([avail_values[f], expert_values[f], collab_values[f]], f) for f in front]\n",
        "  # print(\"crowd is:\",  crowd)\n",
        "\n",
        "  for i in range(3):  # calculate for each fitness function\n",
        "    crowd.sort(key=lambda element: element[0][i])\n",
        "    # print(\"crowd after sort by\", i, crowd)\n",
        "\n",
        "    # After sorting, boundary solutions are assigned Inf \n",
        "    distances[crowd[0][1]] = float(\"Inf\")\n",
        "    distances[crowd[-1][1]] = float(\"inf\")\n",
        "    \n",
        "    if crowd[-1][0][i] == crowd[0][0][i]:  # If objective values are same, skip this loop\n",
        "      continue\n",
        "\n",
        "    norm = float(crowd[-1][0][i] - crowd[0][0][i])   # normalization (max - min) as Denominator\n",
        "\n",
        "    # calculate each individual's Crowding Distance of i th objective\n",
        "    for prev, cur, next in zip(crowd[:-2], crowd[1:-1], crowd[2:]):\n",
        "      distances[cur[1]] += (next[0][i] - prev[0][i]) / norm  # sum up the distance of ith individual along each of the objectives\n",
        "\n",
        "    # print(\"distances:\", distances)\n",
        "\n",
        "  return [distances[i] for i in front]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBWnIO2oUJmJ"
      },
      "source": [
        "# Sort given front in descending order according to crowding distance values\n",
        "def sort_front_by_dist(Availability_values, Expertise_values, Collaboration_values, front):\n",
        "  crowding_distance_values = crowding_distance(Availability_values, Expertise_values, Collaboration_values, front)\n",
        "  \n",
        "  # create a dictionary of each member of F[i] and its corresponding crowding distance\n",
        "  dic = dict(zip(front, crowding_distance_values))\n",
        "\n",
        "  # sort dictionary by values in descending order\n",
        "  sorted_dic = sorted(dic.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  # keys of dictionary are the number of genes\n",
        "  front = [sorted_dic[i][0] for i in range(0, len(sorted_dic))]  # sorted front by crowding distance values\n",
        "  return front"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmtDa9wLDRd2"
      },
      "source": [
        "### Genetic core"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbAXUWk4gfOO"
      },
      "source": [
        "def genetic(P, M, N, files, all_reviewers, all_devs, FR, DR, A, FD, pop_size, max_gen, cross_prob, mute_prob, gene_modif_prob):\n",
        "  # Create initial population\n",
        "  P0 = [init_gene(P, M) for i in range(0, pop_size)]\n",
        "  # print(\"Initial population:\", len(P0))\n",
        "  # print(P0)\n",
        "\n",
        "  t = 0   # generation number\n",
        "\n",
        "  while t < max_gen:   # while stopping criteria not reached\n",
        "  \n",
        "    if t % 10 == 0:\n",
        "      print(\"Generation number:\", t)\n",
        "\n",
        "    # Generating offspring population\n",
        "    Q0 = create_new_pop(P0, pop_size, cross_prob, mute_prob, gene_modif_prob, P, M)\n",
        "    # print(\"Offspring population:\", len(Q0))\n",
        "\n",
        "    R = array(P0 + Q0)     # final population is union of parents and childs\n",
        "    # print(\"R:\", R)\n",
        "    total_pop = len(R)     # number of whole population contains parents and childs that is 2*pop_size (constant number to the end of algorithm)\n",
        "    # print(\"total number of chromosomes:\", total_pop)\n",
        "\n",
        "    # Calculate fitness values for all genes in population\n",
        "    Availability_values = [fit_avail(A, R[i]) for i in range(0, total_pop)]\n",
        "    # print(\"Avails:\", Availability_values)\n",
        "    Expertise_values = [fit_expert(FR, R[i]) for i in range(0, total_pop)]\n",
        "    # print(\"Expertise:\", Expertise_values)\n",
        "    Collaboration_values = [fit_collab(P, M, N, DR, FD, R[i]) for i in range(0, total_pop)]\n",
        "    # print(\"Collaboration:\", Collaboration_values)\n",
        "\n",
        "    # Fast non-dominated sort\n",
        "    F = fast_non_dominated_sort(Availability_values, Expertise_values, Collaboration_values)\n",
        "    # print(\"Fronts:\", F)\n",
        "\n",
        "    P_new = []    # new parent population\n",
        "    i = 0\n",
        "    while len(P_new) + len(F[i]) <= pop_size:\n",
        "      # Apply crowding distance on F[i]   !!!!!!!!\n",
        "      # if (t+1 == max_gen):  # in last generation, sort fronts by crowding distance values to get sorted final solution\n",
        "      #   F[i] = sort_front_by_dist(Availability_values, Expertise_values, Collaboration_values, F[i])\n",
        "      P_new.extend(F[i])   # union of new parents and current front\n",
        "      i += 1\n",
        "      # print(\"new parents:\", P_new)\n",
        "    \n",
        "    # Apply crowding distance on F[i] only. because this front should be splitted\n",
        "    F[i] = sort_front_by_dist(Availability_values, Expertise_values, Collaboration_values, F[i])\n",
        "\n",
        "    # The first pop_size-|P_new| elements of F_i are chosen\n",
        "    parent_indexes = P_new + F[i][0:(pop_size - len(P_new))]\n",
        "    # print(\"Selected parent numbers for next generation:\", parent_indexes)\n",
        "\n",
        "    # corresponding genes of gene numbers kept as parents for next generation\n",
        "    P0 = [R[idx] for idx in parent_indexes]\n",
        "    # print(\"Next solutions:\", P0) \n",
        "    t += 1\n",
        "\n",
        "  # Return solution set\n",
        "  print(\"Final set of solutions:\", P0)     # A set of solutions for problem\n",
        "  return P0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlLVMfhDzVhg"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ0OzQGlNNkI"
      },
      "source": [
        "### load final data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuIchz87KTA4",
        "outputId": "40c0e87c-c8a5-477f-860d-ad600342f557"
      },
      "source": [
        "# Load final data from drive\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/My Project/openstack_final.json',)\n",
        "data = json.load(f)  # returns json object as a dictionary\n",
        "for i in range(5):   # 5 first elements of the json list\n",
        "    print(data[i])\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'time': '2011-07-18 15:43:34', 'changeId': 'Ibb2f047c9c45d011361d253d4444b2fd1ebd3612', 'ownerId': '1', 'reviewersId': ['2'], 'filePaths': ['modules/ssh/files/sshd_config', 'manifests/server.pp', 'modules/ssh/manifests/init.pp']}\n",
            "{'time': '2011-07-18 16:56:22', 'changeId': 'Iea32ad3aedbee996db53655842061d14c9e3d876', 'ownerId': '1', 'reviewersId': ['1'], 'filePaths': ['modules/jenkins_slave/manifests/jenkinsuser.pp', 'modules/jenkins_slave/files/known_hosts']}\n",
            "{'time': '2011-07-18 17:14:05', 'changeId': 'Ib6af08a6af71a6e5853d958a12f63c381eafa039', 'ownerId': '1', 'reviewersId': ['1'], 'filePaths': ['modules/jenkins_slave/manifests/jenkinsuser.pp']}\n",
            "{'time': '2011-07-20 14:37:53', 'changeId': 'Ide7975c522b6b31a23af67b135135c07d75d9bde', 'ownerId': '2', 'reviewersId': ['1'], 'filePaths': ['modules/jenkins_slave/files/pubring.gpg', 'modules/jenkins_slave/manifests/jenkinsuser.pp']}\n",
            "{'time': '2011-07-20 15:12:47', 'changeId': 'I28119ac1735127812866a4b0519368a829e2e666', 'ownerId': '2', 'reviewersId': ['1'], 'filePaths': ['manifests/openstack_ci.pp']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjDt8F7B8uGj",
        "outputId": "e684d773-3b5f-4c86-b5cf-da6f210f01bd"
      },
      "source": [
        "# convert times to datetime format\n",
        "for pr in data:\n",
        "  pr['time'] = parser.parse(pr['time'])\n",
        "\n",
        "data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'changeId': 'Ibb2f047c9c45d011361d253d4444b2fd1ebd3612',\n",
              " 'filePaths': ['modules/ssh/files/sshd_config',\n",
              "  'manifests/server.pp',\n",
              "  'modules/ssh/manifests/init.pp'],\n",
              " 'ownerId': '1',\n",
              " 'reviewersId': ['2'],\n",
              " 'time': datetime.datetime(2011, 7, 18, 15, 43, 34)}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_-nzsBuizst",
        "outputId": "6955294b-46b7-4c1b-c0ab-fc1cafed81bb"
      },
      "source": [
        "# Number of files in whole data\n",
        "all_files = set()   # make a \"set\" of all file paths\n",
        "max_file = 0\n",
        "\n",
        "for pr in data:\n",
        "  num_file = 0\n",
        "  for f in pr['filePaths']:\n",
        "    all_files.add(f)\n",
        "    num_file += 1\n",
        "  if num_file > max_file:\n",
        "    max_file = num_file\n",
        "\n",
        "print(\"Total number of files in dataset:\", len(all_files))\n",
        "print(\"Maximum number of files in a PR:\", max_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of files in dataset: 11421\n",
            "Maximum number of files in a PR: 1757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1wigISqjI1u",
        "outputId": "b80d2bac-d736-4177-ad70-70769a4dee55"
      },
      "source": [
        "# Number of reviewers in whole data\n",
        "all_reviewers = set()   # make a set of all reviewers\n",
        "for pr in data:\n",
        "  for r in pr['reviewersId']:\n",
        "    all_reviewers.add(r)\n",
        "\n",
        "print(\"Total number of reviewers in dataset:\", len(all_reviewers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of reviewers in dataset: 82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O--ZnJJr26mB",
        "outputId": "1183b698-d2b1-49fa-fe86-5c9fddceaeef"
      },
      "source": [
        "# Number of developers in whole data\n",
        "all_devs = set()   # make a \"set\" of all developers\n",
        "for pr in data:\n",
        "  all_devs.add(pr['ownerId'])\n",
        "\n",
        "print(\"Total number of developers in dataset:\", len(all_devs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of developers in dataset: 324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTzNT27Dwsgt"
      },
      "source": [
        "### split train/test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUlPf94X0AxZ"
      },
      "source": [
        "# Split data for train/test sets\n",
        "init_train = data[0:5900]     # 90% of data is for initial train set (5900 PR)\n",
        "total_test = data[5900:6545]  # 10% of data will be tested in the whole examination (645 PR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSVDjK4ow2Gk"
      },
      "source": [
        "### functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYXoLDsGtEdr"
      },
      "source": [
        "def get_files(pr):\n",
        "  # create a \"set\" of file paths in PR. we selected set to ensure not collecting repeated files \n",
        "  return {f for f in pr['filePaths']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us1k9gs4tYBy"
      },
      "source": [
        "def get_all_reviewers(train):\n",
        "  # create a set of all reviewers\n",
        "  all_reviewers = set()   \n",
        "  for pr in train:\n",
        "    for r in pr['reviewersId']:\n",
        "      all_reviewers.add(r)\n",
        "  return all_reviewers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqN9PxUDtlsi"
      },
      "source": [
        "def get_all_devs(train):\n",
        "  # create a \"set\" of all developers \n",
        "  return {pr['ownerId'] for pr in train}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi_k1x69BZH3"
      },
      "source": [
        "### Experiment & Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoYsDcINBq_2"
      },
      "source": [
        "# Function to write predicted top-k reviewers for each test into a JSON file\n",
        "def save_predictions(top_13510, test_num):\n",
        "  predictions = {}\n",
        "  predictions['test_num'] = test_num\n",
        "  predictions[1] = top_13510[0]\n",
        "  predictions[3] = top_13510[1]\n",
        "  predictions[5] = top_13510[2]\n",
        "  predictions[10] = top_13510[3]\n",
        "  with open('output.txt', 'a') as outfile:\n",
        "    json.dump(predictions, outfile, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcvkKOgrlrgp"
      },
      "source": [
        "# Function for saving that predictions are true or flase\n",
        "def save_true_pred(true_pred):\n",
        "  with open('result.txt', 'a') as outfile:\n",
        "    outfile.write(str(true_pred)+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyDAH9ZNB-mG"
      },
      "source": [
        "# Function to predict top-k reviewers for a test PR\n",
        "# Write the answer into a JSON file \n",
        "# Returns a list of zeros and ones. 1 in first position means true prediction for top-1\n",
        "def top_k_answers(solutions, actual_revs_indexes, test_num):\n",
        "\n",
        "  top_13510 = []\n",
        "  k_values = [1, 3, 5, 10]\n",
        "  true_pred = []   # 1 if predicted truly and 0 otherwise\n",
        "\n",
        "  for k in k_values:\n",
        "    found_flag = False\n",
        "    for solution in solutions:  # search in solution set\n",
        "      if not found_flag:\n",
        "\n",
        "        # total_top_k is a set of top k reviewers for all files in PR\n",
        "        total_top_k = {r for f in range(P) for r in range(M) if 1 <= solution[f][r] <= k}  \n",
        "        # print(total_top_k)\n",
        "\n",
        "        top_ks = set(itertools.combinations(total_top_k, k))   # top_ks is exactly all possible k best reviewers as predicted answer for PR (all subsets with size k of total_top_k)\n",
        "        # print(top_ks)\n",
        "\n",
        "        for top_k in top_ks:   # top k predicted answers (each of them is the predicted answer)\n",
        "          if actual_revs_indexes.issubset(set(top_k)) or set(top_k).issubset(actual_revs_indexes):   # this reviewer is in the correct solution of this test\n",
        "            # answer found\n",
        "            top_13510.append([all_reviewers[t] for t in set(top_k)])\n",
        "            true_pred.append(1)\n",
        "            print(\"top\", k, \"reviewers found correctly in index:\", set(top_k))\n",
        "            found_flag = True  # stop searching in other solutions\n",
        "            break  # no need to search in other files\n",
        "\n",
        "    # answer not found for this k\n",
        "    if not found_flag:\n",
        "      top_13510.append([all_reviewers[t] for t in set(top_k)])\n",
        "      if actual_revs_indexes.issubset(set(top_k)): \n",
        "        true_pred.append(1)  # answer found\n",
        "        print(\"top\", k, \"reviewers found correctly in index:\", set(top_k))\n",
        "      else:\n",
        "        true_pred.append(0)\n",
        "\n",
        "    print(\"up to k\", k, top_13510)\n",
        "\n",
        "  save_predictions(top_13510, test_num)   # write predicted answers into file\n",
        "  return true_pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfZovQEICc9P"
      },
      "source": [
        "# Function to calculate Precision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb4l2rjoCgpW"
      },
      "source": [
        "# Function to calculate Recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA-DmUuGTwdQ"
      },
      "source": [
        "# # 20 and 600  -> 39 mins\n",
        "# k = 1  # top-1\n",
        "# for solution in solutions:  # search in solution set\n",
        "#   top_k = set()\n",
        "#   for f in range(0, P):     # solution for each file\n",
        "#     for r in range(0, M):   # each rank for each file\n",
        "#       if 1 <= solution[f][r] <= k:\n",
        "#         top_k.add(r)\n",
        "#     # print(top_k)\n",
        "#     if len(top_k) != 0 and ((all_revs_indexes.issubset(top_k)) or top_k.issubset(all_revs_indexes)):   # this reviewer is in the correct solution of this test\n",
        "#       print(\"found in:\", solution)\n",
        "#       break  # no need to search in other files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udQDcGXPw6Tr"
      },
      "source": [
        "### main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUaGN-pf_fDR",
        "outputId": "8d45c61d-d526-4fde-b052-d73472cd1c5b"
      },
      "source": [
        "for test_num in range(0, 100):  # number of examination can be 0 to 644\n",
        "\n",
        "  print(\"************ Test\", test_num, \"************\")\n",
        "  # creating test set\n",
        "  test = total_test[test_num]   # one PR is test in each examination\n",
        "  # creating train set\n",
        "  if test_num == 0:  # must be 0 ********** change it for each run for now **********\n",
        "    train = init_train\n",
        "    # train.extend(total_test[0:test_num])  # must romved\n",
        "  else:\n",
        "    train.append(total_test[test_num-1])\n",
        "\n",
        "  # test = total_test[1]\n",
        "  # train = init_train[0:5901]\n",
        "\n",
        "  # other calculations\n",
        "  files = list(get_files(test))\n",
        "  P = len(files)\n",
        "  # print(files, \"P is:\", P)\n",
        "\n",
        "  all_reviewers = list(get_all_reviewers(train))\n",
        "  M = len(all_reviewers)\n",
        "  # print(all_reviewers, \"M is:\", M)\n",
        "\n",
        "  all_devs = list(get_all_devs(train))\n",
        "  N = len(all_devs)\n",
        "  # print(all_devs, \"N is:\", N)\n",
        "\n",
        "  # Extract 3 metrices just one time\n",
        "  FR = cal_expertise(files, all_reviewers, train)          # File-Reviewer matrix\n",
        "  DR = cal_collaboration(all_devs, all_reviewers, train)   # Developer-Reviwer matrix\n",
        "  A = cal_availability(all_reviewers, train, test['time']) # Availability vector\n",
        "  FD = cal_fileDev(all_devs, files, train)                 # File-Developer matrix\n",
        "\n",
        "  # Run Genetic on test PR\n",
        "  # pop_size: test for 10, 20, 30, 40, 50\n",
        "  # max_gen : stopping criterion = 100,000 fitness evaluations\n",
        "  # cross_prob: crossover probability\n",
        "  # mute_prob : mutation probabillity\n",
        "  # gene_modif_prob: probability of gene modification\n",
        "  if len(test['filePaths']) >= 6:\n",
        "    solutions = genetic(P, M, N, files, all_reviewers, all_devs, FR, DR, A, FD, pop_size=10, max_gen=200, cross_prob=0.5, mute_prob=0.4, gene_modif_prob=0.2)\n",
        "  else:\n",
        "    solutions = genetic(P, M, N, files, all_reviewers, all_devs, FR, DR, A, FD, pop_size=30, max_gen=100, cross_prob=0.5, mute_prob=0.4, gene_modif_prob=0.2)\n",
        "\n",
        "  # Run top_k_answers function for k=1, 3, 5, 10\n",
        "  print(\"************ Results ************\")\n",
        "  actual_revs_indexes = {all_reviewers.index(r) if r in all_reviewers else -1 for r in test['reviewersId']}\n",
        "  if -1 in actual_revs_indexes:\n",
        "    actual_revs_indexes.remove(-1)\n",
        "  if len(actual_revs_indexes) != 0:\n",
        "    true_preds = top_k_answers(solutions, actual_revs_indexes, test_num)\n",
        "    print(\"True predictions for test number\", test_num, \"are:\", true_preds)\n",
        "  else:   # reviewers of this test are all new people\n",
        "    top_k_answers(solutions, actual_revs_indexes, test_num)\n",
        "    true_preds = [0, 0, 0, 0]\n",
        "  save_true_pred(true_preds)\n",
        "\n",
        "  # Calculate precision and recall\n",
        "  # TODO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************ Test 99 ************\n",
            "Generation number: 0\n",
            "Generation number: 10\n",
            "Generation number: 20\n",
            "Generation number: 30\n",
            "Generation number: 40\n",
            "Generation number: 50\n",
            "Generation number: 60\n",
            "Generation number: 70\n",
            "Generation number: 80\n",
            "Generation number: 90\n",
            "Final set of solutions: [array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])]\n",
            "************ Results ************\n",
            "up to k 1 [['642']]\n",
            "up to k 3 [['642'], ['642']]\n",
            "up to k 5 [['642'], ['642'], ['642']]\n",
            "up to k 10 [['642'], ['642'], ['642'], ['642']]\n",
            "True predictions for test number 99 are: [0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO6ZgCoBIX70"
      },
      "source": [
        "# Simple test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvMZIerjIKDJ",
        "outputId": "5c027d26-2cb2-4f5b-f2af-4172b9db5aed"
      },
      "source": [
        "test = {'changeId': '4',\n",
        "        'filePaths': ['a.py', 'c.py'],\n",
        "        'ownerId': '3',\n",
        "        'reviewersId': ['0', '4'],\n",
        "        'time': '2012-05-11 22:22:22'}\n",
        "\n",
        "train = [{'changeId': '0',\n",
        "        'filePaths': ['a.py', 'b.py'],\n",
        "        'ownerId': '2',\n",
        "        'reviewersId': ['0'],\n",
        "        'time': '2012-05-9 22:22:22'},\n",
        "        {'changeId': '1',\n",
        "        'filePaths': ['c.py'],\n",
        "        'ownerId': '3',\n",
        "        'reviewersId': ['4'],\n",
        "        'time': '2012-05-10 22:22:22'}]\n",
        "        \n",
        "for pr in train:\n",
        "  pr['time'] = parser.parse(pr['time'])\n",
        "test['time'] = parser.parse(test['time'])\n",
        "\n",
        "# other calculations\n",
        "files = ['c.py', 'a.py']\n",
        "P = 2\n",
        "\n",
        "all_reviewers = ['0', '4']\n",
        "M = 2\n",
        "\n",
        "all_devs = ['3', '2']\n",
        "N = 2\n",
        "\n",
        "# Extract 3 metrices just one time\n",
        "FR = array([[0, 1],[1, 0]])       \n",
        "DR = array([[0, 1],[2, 0]]) \n",
        "A = [2, 1]\n",
        "FD = array([[1, 0],[0, 1]])\n",
        "print(\"Shape of FR matrix is:\", FR.shape)\n",
        "print(FR)\n",
        "print(\"Shape of DR matrix is:\", DR.shape)\n",
        "print(DR)\n",
        "print(\"Size of A matrix is:\", len(A))\n",
        "print(A)\n",
        "print(\"Shape of FD matrix is:\", FD.shape)\n",
        "print(FD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of FR matrix is: (2, 2)\n",
            "[[0 1]\n",
            " [1 0]]\n",
            "Shape of DR matrix is: (2, 2)\n",
            "[[0 1]\n",
            " [2 0]]\n",
            "Size of A matrix is: 2\n",
            "[2, 1]\n",
            "Shape of FD matrix is: (2, 2)\n",
            "[[1 0]\n",
            " [0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPFeA_0NTedM",
        "outputId": "84617b60-2a99-46fb-cc0c-4114a83cd1fe"
      },
      "source": [
        "solutions = genetic(P, M, N, files, all_reviewers, all_devs, FR, DR, A, FD, pop_size=10, max_gen=500, cross_prob=0.5, mute_prob=0.4, gene_modif_prob=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generation number: 0\n",
            "Generation number: 1\n",
            "Generation number: 2\n",
            "Generation number: 3\n",
            "Generation number: 4\n",
            "Generation number: 5\n",
            "Generation number: 6\n",
            "Generation number: 7\n",
            "Generation number: 8\n",
            "Generation number: 9\n",
            "Generation number: 10\n",
            "Generation number: 11\n",
            "Generation number: 12\n",
            "Generation number: 13\n",
            "Generation number: 14\n",
            "Generation number: 15\n",
            "Generation number: 16\n",
            "Generation number: 17\n",
            "Generation number: 18\n",
            "Generation number: 19\n",
            "Generation number: 20\n",
            "Generation number: 21\n",
            "Generation number: 22\n",
            "Generation number: 23\n",
            "Generation number: 24\n",
            "Generation number: 25\n",
            "Generation number: 26\n",
            "Generation number: 27\n",
            "Generation number: 28\n",
            "Generation number: 29\n",
            "Generation number: 30\n",
            "Generation number: 31\n",
            "Generation number: 32\n",
            "Generation number: 33\n",
            "Generation number: 34\n",
            "Generation number: 35\n",
            "Generation number: 36\n",
            "Generation number: 37\n",
            "Generation number: 38\n",
            "Generation number: 39\n",
            "Generation number: 40\n",
            "Generation number: 41\n",
            "Generation number: 42\n",
            "Generation number: 43\n",
            "Generation number: 44\n",
            "Generation number: 45\n",
            "Generation number: 46\n",
            "Generation number: 47\n",
            "Generation number: 48\n",
            "Generation number: 49\n",
            "Generation number: 50\n",
            "Generation number: 51\n",
            "Generation number: 52\n",
            "Generation number: 53\n",
            "Generation number: 54\n",
            "Generation number: 55\n",
            "Generation number: 56\n",
            "Generation number: 57\n",
            "Generation number: 58\n",
            "Generation number: 59\n",
            "Generation number: 60\n",
            "Generation number: 61\n",
            "Generation number: 62\n",
            "Generation number: 63\n",
            "Generation number: 64\n",
            "Generation number: 65\n",
            "Generation number: 66\n",
            "Generation number: 67\n",
            "Generation number: 68\n",
            "Generation number: 69\n",
            "Generation number: 70\n",
            "Generation number: 71\n",
            "Generation number: 72\n",
            "Generation number: 73\n",
            "Generation number: 74\n",
            "Generation number: 75\n",
            "Generation number: 76\n",
            "Generation number: 77\n",
            "Generation number: 78\n",
            "Generation number: 79\n",
            "Generation number: 80\n",
            "Generation number: 81\n",
            "Generation number: 82\n",
            "Generation number: 83\n",
            "Generation number: 84\n",
            "Generation number: 85\n",
            "Generation number: 86\n",
            "Generation number: 87\n",
            "Generation number: 88\n",
            "Generation number: 89\n",
            "Generation number: 90\n",
            "Generation number: 91\n",
            "Generation number: 92\n",
            "Generation number: 93\n",
            "Generation number: 94\n",
            "Generation number: 95\n",
            "Generation number: 96\n",
            "Generation number: 97\n",
            "Generation number: 98\n",
            "Generation number: 99\n",
            "Generation number: 100\n",
            "Generation number: 101\n",
            "Generation number: 102\n",
            "Generation number: 103\n",
            "Generation number: 104\n",
            "Generation number: 105\n",
            "Generation number: 106\n",
            "Generation number: 107\n",
            "Generation number: 108\n",
            "Generation number: 109\n",
            "Generation number: 110\n",
            "Generation number: 111\n",
            "Generation number: 112\n",
            "Generation number: 113\n",
            "Generation number: 114\n",
            "Generation number: 115\n",
            "Generation number: 116\n",
            "Generation number: 117\n",
            "Generation number: 118\n",
            "Generation number: 119\n",
            "Generation number: 120\n",
            "Generation number: 121\n",
            "Generation number: 122\n",
            "Generation number: 123\n",
            "Generation number: 124\n",
            "Generation number: 125\n",
            "Generation number: 126\n",
            "Generation number: 127\n",
            "Generation number: 128\n",
            "Generation number: 129\n",
            "Generation number: 130\n",
            "Generation number: 131\n",
            "Generation number: 132\n",
            "Generation number: 133\n",
            "Generation number: 134\n",
            "Generation number: 135\n",
            "Generation number: 136\n",
            "Generation number: 137\n",
            "Generation number: 138\n",
            "Generation number: 139\n",
            "Generation number: 140\n",
            "Generation number: 141\n",
            "Generation number: 142\n",
            "Generation number: 143\n",
            "Generation number: 144\n",
            "Generation number: 145\n",
            "Generation number: 146\n",
            "Generation number: 147\n",
            "Generation number: 148\n",
            "Generation number: 149\n",
            "Generation number: 150\n",
            "Generation number: 151\n",
            "Generation number: 152\n",
            "Generation number: 153\n",
            "Generation number: 154\n",
            "Generation number: 155\n",
            "Generation number: 156\n",
            "Generation number: 157\n",
            "Generation number: 158\n",
            "Generation number: 159\n",
            "Generation number: 160\n",
            "Generation number: 161\n",
            "Generation number: 162\n",
            "Generation number: 163\n",
            "Generation number: 164\n",
            "Generation number: 165\n",
            "Generation number: 166\n",
            "Generation number: 167\n",
            "Generation number: 168\n",
            "Generation number: 169\n",
            "Generation number: 170\n",
            "Generation number: 171\n",
            "Generation number: 172\n",
            "Generation number: 173\n",
            "Generation number: 174\n",
            "Generation number: 175\n",
            "Generation number: 176\n",
            "Generation number: 177\n",
            "Generation number: 178\n",
            "Generation number: 179\n",
            "Generation number: 180\n",
            "Generation number: 181\n",
            "Generation number: 182\n",
            "Generation number: 183\n",
            "Generation number: 184\n",
            "Generation number: 185\n",
            "Generation number: 186\n",
            "Generation number: 187\n",
            "Generation number: 188\n",
            "Generation number: 189\n",
            "Generation number: 190\n",
            "Generation number: 191\n",
            "Generation number: 192\n",
            "Generation number: 193\n",
            "Generation number: 194\n",
            "Generation number: 195\n",
            "Generation number: 196\n",
            "Generation number: 197\n",
            "Generation number: 198\n",
            "Generation number: 199\n",
            "Generation number: 200\n",
            "Generation number: 201\n",
            "Generation number: 202\n",
            "Generation number: 203\n",
            "Generation number: 204\n",
            "Generation number: 205\n",
            "Generation number: 206\n",
            "Generation number: 207\n",
            "Generation number: 208\n",
            "Generation number: 209\n",
            "Generation number: 210\n",
            "Generation number: 211\n",
            "Generation number: 212\n",
            "Generation number: 213\n",
            "Generation number: 214\n",
            "Generation number: 215\n",
            "Generation number: 216\n",
            "Generation number: 217\n",
            "Generation number: 218\n",
            "Generation number: 219\n",
            "Generation number: 220\n",
            "Generation number: 221\n",
            "Generation number: 222\n",
            "Generation number: 223\n",
            "Generation number: 224\n",
            "Generation number: 225\n",
            "Generation number: 226\n",
            "Generation number: 227\n",
            "Generation number: 228\n",
            "Generation number: 229\n",
            "Generation number: 230\n",
            "Generation number: 231\n",
            "Generation number: 232\n",
            "Generation number: 233\n",
            "Generation number: 234\n",
            "Generation number: 235\n",
            "Generation number: 236\n",
            "Generation number: 237\n",
            "Generation number: 238\n",
            "Generation number: 239\n",
            "Generation number: 240\n",
            "Generation number: 241\n",
            "Generation number: 242\n",
            "Generation number: 243\n",
            "Generation number: 244\n",
            "Generation number: 245\n",
            "Generation number: 246\n",
            "Generation number: 247\n",
            "Generation number: 248\n",
            "Generation number: 249\n",
            "Generation number: 250\n",
            "Generation number: 251\n",
            "Generation number: 252\n",
            "Generation number: 253\n",
            "Generation number: 254\n",
            "Generation number: 255\n",
            "Generation number: 256\n",
            "Generation number: 257\n",
            "Generation number: 258\n",
            "Generation number: 259\n",
            "Generation number: 260\n",
            "Generation number: 261\n",
            "Generation number: 262\n",
            "Generation number: 263\n",
            "Generation number: 264\n",
            "Generation number: 265\n",
            "Generation number: 266\n",
            "Generation number: 267\n",
            "Generation number: 268\n",
            "Generation number: 269\n",
            "Generation number: 270\n",
            "Generation number: 271\n",
            "Generation number: 272\n",
            "Generation number: 273\n",
            "Generation number: 274\n",
            "Generation number: 275\n",
            "Generation number: 276\n",
            "Generation number: 277\n",
            "Generation number: 278\n",
            "Generation number: 279\n",
            "Generation number: 280\n",
            "Generation number: 281\n",
            "Generation number: 282\n",
            "Generation number: 283\n",
            "Generation number: 284\n",
            "Generation number: 285\n",
            "Generation number: 286\n",
            "Generation number: 287\n",
            "Generation number: 288\n",
            "Generation number: 289\n",
            "Generation number: 290\n",
            "Generation number: 291\n",
            "Generation number: 292\n",
            "Generation number: 293\n",
            "Generation number: 294\n",
            "Generation number: 295\n",
            "Generation number: 296\n",
            "Generation number: 297\n",
            "Generation number: 298\n",
            "Generation number: 299\n",
            "Generation number: 300\n",
            "Generation number: 301\n",
            "Generation number: 302\n",
            "Generation number: 303\n",
            "Generation number: 304\n",
            "Generation number: 305\n",
            "Generation number: 306\n",
            "Generation number: 307\n",
            "Generation number: 308\n",
            "Generation number: 309\n",
            "Generation number: 310\n",
            "Generation number: 311\n",
            "Generation number: 312\n",
            "Generation number: 313\n",
            "Generation number: 314\n",
            "Generation number: 315\n",
            "Generation number: 316\n",
            "Generation number: 317\n",
            "Generation number: 318\n",
            "Generation number: 319\n",
            "Generation number: 320\n",
            "Generation number: 321\n",
            "Generation number: 322\n",
            "Generation number: 323\n",
            "Generation number: 324\n",
            "Generation number: 325\n",
            "Generation number: 326\n",
            "Generation number: 327\n",
            "Generation number: 328\n",
            "Generation number: 329\n",
            "Generation number: 330\n",
            "Generation number: 331\n",
            "Generation number: 332\n",
            "Generation number: 333\n",
            "Generation number: 334\n",
            "Generation number: 335\n",
            "Generation number: 336\n",
            "Generation number: 337\n",
            "Generation number: 338\n",
            "Generation number: 339\n",
            "Generation number: 340\n",
            "Generation number: 341\n",
            "Generation number: 342\n",
            "Generation number: 343\n",
            "Generation number: 344\n",
            "Generation number: 345\n",
            "Generation number: 346\n",
            "Generation number: 347\n",
            "Generation number: 348\n",
            "Generation number: 349\n",
            "Generation number: 350\n",
            "Generation number: 351\n",
            "Generation number: 352\n",
            "Generation number: 353\n",
            "Generation number: 354\n",
            "Generation number: 355\n",
            "Generation number: 356\n",
            "Generation number: 357\n",
            "Generation number: 358\n",
            "Generation number: 359\n",
            "Generation number: 360\n",
            "Generation number: 361\n",
            "Generation number: 362\n",
            "Generation number: 363\n",
            "Generation number: 364\n",
            "Generation number: 365\n",
            "Generation number: 366\n",
            "Generation number: 367\n",
            "Generation number: 368\n",
            "Generation number: 369\n",
            "Generation number: 370\n",
            "Generation number: 371\n",
            "Generation number: 372\n",
            "Generation number: 373\n",
            "Generation number: 374\n",
            "Generation number: 375\n",
            "Generation number: 376\n",
            "Generation number: 377\n",
            "Generation number: 378\n",
            "Generation number: 379\n",
            "Generation number: 380\n",
            "Generation number: 381\n",
            "Generation number: 382\n",
            "Generation number: 383\n",
            "Generation number: 384\n",
            "Generation number: 385\n",
            "Generation number: 386\n",
            "Generation number: 387\n",
            "Generation number: 388\n",
            "Generation number: 389\n",
            "Generation number: 390\n",
            "Generation number: 391\n",
            "Generation number: 392\n",
            "Generation number: 393\n",
            "Generation number: 394\n",
            "Generation number: 395\n",
            "Generation number: 396\n",
            "Generation number: 397\n",
            "Generation number: 398\n",
            "Generation number: 399\n",
            "Generation number: 400\n",
            "Generation number: 401\n",
            "Generation number: 402\n",
            "Generation number: 403\n",
            "Generation number: 404\n",
            "Generation number: 405\n",
            "Generation number: 406\n",
            "Generation number: 407\n",
            "Generation number: 408\n",
            "Generation number: 409\n",
            "Generation number: 410\n",
            "Generation number: 411\n",
            "Generation number: 412\n",
            "Generation number: 413\n",
            "Generation number: 414\n",
            "Generation number: 415\n",
            "Generation number: 416\n",
            "Generation number: 417\n",
            "Generation number: 418\n",
            "Generation number: 419\n",
            "Generation number: 420\n",
            "Generation number: 421\n",
            "Generation number: 422\n",
            "Generation number: 423\n",
            "Generation number: 424\n",
            "Generation number: 425\n",
            "Generation number: 426\n",
            "Generation number: 427\n",
            "Generation number: 428\n",
            "Generation number: 429\n",
            "Generation number: 430\n",
            "Generation number: 431\n",
            "Generation number: 432\n",
            "Generation number: 433\n",
            "Generation number: 434\n",
            "Generation number: 435\n",
            "Generation number: 436\n",
            "Generation number: 437\n",
            "Generation number: 438\n",
            "Generation number: 439\n",
            "Generation number: 440\n",
            "Generation number: 441\n",
            "Generation number: 442\n",
            "Generation number: 443\n",
            "Generation number: 444\n",
            "Generation number: 445\n",
            "Generation number: 446\n",
            "Generation number: 447\n",
            "Generation number: 448\n",
            "Generation number: 449\n",
            "Generation number: 450\n",
            "Generation number: 451\n",
            "Generation number: 452\n",
            "Generation number: 453\n",
            "Generation number: 454\n",
            "Generation number: 455\n",
            "Generation number: 456\n",
            "Generation number: 457\n",
            "Generation number: 458\n",
            "Generation number: 459\n",
            "Generation number: 460\n",
            "Generation number: 461\n",
            "Generation number: 462\n",
            "Generation number: 463\n",
            "Generation number: 464\n",
            "Generation number: 465\n",
            "Generation number: 466\n",
            "Generation number: 467\n",
            "Generation number: 468\n",
            "Generation number: 469\n",
            "Generation number: 470\n",
            "Generation number: 471\n",
            "Generation number: 472\n",
            "Generation number: 473\n",
            "Generation number: 474\n",
            "Generation number: 475\n",
            "Generation number: 476\n",
            "Generation number: 477\n",
            "Generation number: 478\n",
            "Generation number: 479\n",
            "Generation number: 480\n",
            "Generation number: 481\n",
            "Generation number: 482\n",
            "Generation number: 483\n",
            "Generation number: 484\n",
            "Generation number: 485\n",
            "Generation number: 486\n",
            "Generation number: 487\n",
            "Generation number: 488\n",
            "Generation number: 489\n",
            "Generation number: 490\n",
            "Generation number: 491\n",
            "Generation number: 492\n",
            "Generation number: 493\n",
            "Generation number: 494\n",
            "Generation number: 495\n",
            "Generation number: 496\n",
            "Generation number: 497\n",
            "Generation number: 498\n",
            "Generation number: 499\n",
            "Final ordered set of solutions: [array([[0, 1],\n",
            "       [0, 1]]), array([[0, 1],\n",
            "       [1, 2]]), array([[0, 1],\n",
            "       [0, 1]]), array([[0, 1],\n",
            "       [1, 2]]), array([[0, 1],\n",
            "       [0, 1]]), array([[0, 1],\n",
            "       [1, 2]]), array([[0, 1],\n",
            "       [0, 1]]), array([[0, 1],\n",
            "       [1, 2]]), array([[0, 1],\n",
            "       [1, 2]]), array([[0, 1],\n",
            "       [0, 1]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8M_trdWnjYk",
        "outputId": "b1b10966-016f-42e3-b08e-e704e22948a8"
      },
      "source": [
        "actual_revs_indexes = {all_reviewers.index(r) for r in test['reviewersId']}\n",
        "print(actual_revs_indexes)\n",
        "top_k_answers(solutions, actual_revs_indexes, 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0, 1}\n",
            "top 1 reviewers are in index: {1}\n",
            "[['4']]\n",
            "[['4'], ['4']]\n",
            "[['4'], ['4'], ['4']]\n",
            "[['4'], ['4'], ['4'], ['4']]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyfnVeYrJ0pB",
        "outputId": "003b8fa8-e9d4-4d9a-dff8-a037df91d325"
      },
      "source": [
        "R = [array([[1,0],[0,1]]),\n",
        "     array([[2,1],[1,2]]),\n",
        "     array([[1,2],[1,2]]),\n",
        "     array([[2,1],[0,1]]),\n",
        "     array([[1,2],[2,1]]),\n",
        "     array([[1,2],[0,1]]),\n",
        "     array([[0,1],[1,0]]),\n",
        "     array([[1,0],[2,1]])]\n",
        "R"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[1, 0],\n",
              "        [0, 1]]), array([[2, 1],\n",
              "        [1, 2]]), array([[1, 2],\n",
              "        [1, 2]]), array([[2, 1],\n",
              "        [0, 1]]), array([[1, 2],\n",
              "        [2, 1]]), array([[1, 2],\n",
              "        [0, 1]]), array([[0, 1],\n",
              "        [1, 0]]), array([[1, 0],\n",
              "        [2, 1]])]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIuO4O0EJTyo"
      },
      "source": [
        "pop_size=4\n",
        "total_pop=2*pop_size\n",
        "max_gen=1\n",
        "cross_prob=0.5\n",
        "mute_prob=0.4\n",
        "gene_modif_prob=0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4O9IqdsOLQL",
        "outputId": "3192a932-49e4-49d4-fbe4-a9b02aae31ef"
      },
      "source": [
        "# Calculate fitness values for all genes in population\n",
        "Availability_values = [fit_avail(A, R[i]) for i in range(0, total_pop)]\n",
        "print(\"Avails:\", Availability_values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avails: [0.3333333333333333, 0.1111111111111111, 0.125, 0.16666666666666666, 0.1111111111111111, 0.2, 0.3333333333333333, 0.14285714285714285]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLXFEmjFOPFh",
        "outputId": "30a5da2d-97dd-47ec-84d4-d31033dc01c4"
      },
      "source": [
        "Expertise_values = [fit_expert(FR, R[i]) for i in range(0, total_pop)]\n",
        "print(\"Expertise:\", Expertise_values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expertise: [0.0, 2.0, 1.5, 1.0, 1.0, 0.5, 2.0, 0.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bNRSnZROXjC",
        "outputId": "ba6873d1-9e92-4a96-f664-44157d55c1de"
      },
      "source": [
        "Collaboration_values = [fit_collab(P, M, N, DR, FD, R[i]) for i in range(0, total_pop)]\n",
        "print(\"Collaboration:\", Collaboration_values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collaboration: [0, 3, 3, 1, 3, 1, 3, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgsQO8okREpT",
        "outputId": "23924db1-b74d-41ce-8bc1-b3a0e3d8cd60"
      },
      "source": [
        "# Fast non-dominated sort\n",
        "F = fast_non_dominated_sort(Availability_values, Expertise_values, Collaboration_values)\n",
        "print(\"Fronts:\", F)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fronts: [[0, 3, 5, 6], [7, 1, 2], [4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WrkzVFRRLSq",
        "outputId": "f0f46ba5-4619-4292-a70a-c3dce8cc0f49"
      },
      "source": [
        "P_new = []    # new parent population\n",
        "i = 0\n",
        "while len(P_new) + len(F[i]) <= pop_size:\n",
        "  F[i] = sort_front_by_dist(Availability_values, Expertise_values, Collaboration_values, F[i])\n",
        "  P_new.extend(F[i])   # union of new parents and current front\n",
        "  i += 1\n",
        "  print(\"new parents:\", P_new)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "new parents: [0, 3, 6, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrZpCsm2JmTx",
        "outputId": "ea0b0501-ff8f-4685-c863-7be936dc8ae9"
      },
      "source": [
        "# Apply crowding distance on F[i] only. because this front should be splitted\n",
        "F[i] = sort_front_by_dist(Availability_values, Expertise_values, Collaboration_values, F[i])\n",
        "F[i]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[7, 1, 2]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQvq_sS8RPlI",
        "outputId": "fa2a4662-2126-464c-9e54-a4ef03b1756a"
      },
      "source": [
        "# The first pop_size-|P_new| elements of F_i are chosen\n",
        "remain = pop_size - len(P_new)\n",
        "parent_indexes = P_new + F[i][0:remain]\n",
        "print(\"Selected parent numbers for next generation:\", parent_indexes)\n",
        "\n",
        "# corresponding genes of gene numbers kept as parents for next generation\n",
        "P0 = [R[idx] for idx in parent_indexes]\n",
        "print(\"Next solutions:\", P0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected parent numbers for next generation: [0, 3, 6, 5]\n",
            "Next solutions: [array([[1, 0],\n",
            "       [0, 1]]), array([[2, 1],\n",
            "       [0, 1]]), array([[0, 1],\n",
            "       [1, 0]]), array([[1, 2],\n",
            "       [0, 1]])]\n"
          ]
        }
      ]
    }
  ]
}